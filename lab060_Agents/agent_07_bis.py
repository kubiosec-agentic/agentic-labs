# Generated by Copilot
from agents import Agent, Runner, AgentOutputSchema
from pydantic import BaseModel, Field, ConfigDict
import asyncio
import json
import os
from typing import List, Dict, Optional

# Load the document
with open("data/docker-curl-https.txt", "r", encoding="utf-8") as f:
    text = f.read()

class AnalysisTask(BaseModel):
    """Task structure for the orchestrator."""
    model_config = ConfigDict(extra='forbid')
    
    task_type: str
    agent_name: str
    instructions: str
    input_data: str
    depends_on: List[str] = Field(default_factory=list)
    parallel_group: Optional[str] = None

class OrchestratorPlan(BaseModel):
    """Orchestration plan structure."""
    model_config = ConfigDict(extra='forbid')
    
    total_tasks: int
    execution_order: List[str]
    parallel_groups: Dict[str, List[str]]
    estimated_duration: str

# Orchestrator Agent - controls the entire workflow
orchestrator_agent = Agent(
    name="Security Analysis Orchestrator",
    model="gpt-4o-mini",
    instructions="""You are a workflow orchestrator for security trace analysis.

Given a sysdig trace file, create an execution plan with these tasks:
1. ANALYZE - Deep security analysis of the trace
2. SUMMARIZE - Create markdown summary 
3. STRUCTURE - Format as detailed JSON

Plan the workflow considering:
- Task dependencies (SUMMARIZE and STRUCTURE depend on ANALYZE)
- Parallel execution opportunities (SUMMARIZE and STRUCTURE can run in parallel)
- Resource optimization
- Error handling strategies

Return a structured plan with task definitions, execution order, and timing estimates.

Example response:
{
  "total_tasks": 3,
  "execution_order": ["ANALYZE", "SUMMARIZE_AND_STRUCTURE"],
  "parallel_groups": {"SUMMARIZE_AND_STRUCTURE": ["SUMMARIZE", "STRUCTURE"]},
  "estimated_duration": "2-3 minutes"
}""",
    output_type=AgentOutputSchema(OrchestratorPlan, strict_json_schema=False)
)

# Worker Agents (same as before but simplified)
analyzer_agent = Agent(
    name="Security Trace Analyzer",
    model="gpt-4o-mini",
    instructions="""Analyze sysdig trace data and extract:
1. Process execution details
2. System call patterns  
3. Network activity
4. File operations
5. Security observations with line numbers

Provide comprehensive analysis with specific line references."""
)

summary_agent = Agent(
    name="Summary Generator", 
    model="gpt-4o-mini",
    instructions="""Create a concise markdown summary including:
- Executive summary
- Key findings and phases
- Security implications
- Timeline of events

Format as clean markdown."""
)

json_agent = Agent(
    name="JSON Formatter",
    model="gpt-4o-mini",
    instructions="""Structure security analysis into detailed JSON with:
- metadata, summary, process_info
- phases, network_activity, file_operations
- security_observations with line numbers

Output only valid JSON."""
)

async def run_orchestrated_analysis():
    """Run orchestrator-controlled security analysis."""
    
    print("üìã Step 1: Creating execution plan...")
    
    # Get orchestration plan
    plan_run_result = await Runner.run(
        orchestrator_agent,
        f"Create execution plan for analyzing this sysdig trace:\n\n{text[:2000]}..."
    )
    
    # Extract the actual plan data from the RunResult
    plan_result = plan_run_result.final_output
    
    print(f"‚úÖ Plan created: {plan_result.total_tasks} tasks")
    print(f"üìä Execution order: {' ‚Üí '.join(plan_result.execution_order)}")
    print(f"‚è±Ô∏è  Estimated duration: {plan_result.estimated_duration}")
    
    if plan_result.parallel_groups:
        print(f"üîÑ Parallel groups: {list(plan_result.parallel_groups.keys())}")
    
    print("\nüìã Step 2: Orchestrator delegating tasks...")
    
    # Create a mapping of task names to agents
    task_agents = {
        "ANALYZE": analyzer_agent,
        "SUMMARIZE": summary_agent,
        "STRUCTURE": json_agent
    }
    
    # Storage for intermediate results
    task_results = {}
    
    # Execute tasks according to the orchestrator's plan
    for step in plan_result.execution_order:
        if step in plan_result.parallel_groups:
            # Handle parallel execution group
            parallel_tasks = plan_result.parallel_groups[step]
            print(f"ÔøΩ Orchestrator executing parallel group '{step}': {parallel_tasks}")
            
            # Create tasks for parallel execution
            async_tasks = []
            for task_name in parallel_tasks:
                if task_name == "ANALYZE":
                    # Analysis uses the original text
                    async_tasks.append(
                        Runner.run(task_agents[task_name], text)
                    )
                elif task_name in ["SUMMARIZE", "STRUCTURE"]:
                    # These depend on analysis results
                    if "ANALYZE" in task_results:
                        async_tasks.append(
                            Runner.run(task_agents[task_name], task_results["ANALYZE"])
                        )
                    else:
                        print(f"‚ö†Ô∏è  Warning: {task_name} depends on ANALYZE but no analysis results available")
                        continue
            
            # Execute parallel tasks
            if async_tasks:
                parallel_results = await asyncio.gather(*async_tasks)
                for i, task_name in enumerate([t for t in parallel_tasks if t in task_agents]):
                    if i < len(parallel_results):
                        task_results[task_name] = parallel_results[i].final_output
                        print(f"‚úÖ Orchestrator completed: {task_name}")
        
        elif step in task_agents:
            # Handle individual task
            print(f"üéØ Orchestrator executing: {step}")
            
            if step == "ANALYZE":
                # Analysis uses the original text
                result = await Runner.run(task_agents[step], text)
                task_results[step] = result.final_output
            elif step in ["SUMMARIZE", "STRUCTURE"]:
                # These depend on analysis results
                if "ANALYZE" in task_results:
                    result = await Runner.run(task_agents[step], task_results["ANALYZE"])
                    task_results[step] = result.final_output
                else:
                    print(f"‚ö†Ô∏è  Warning: {step} depends on ANALYZE but no analysis results available")
                    continue
            
            print(f"‚úÖ Orchestrator completed: {step}")
        
        else:
            print(f"‚ö†Ô∏è  Unknown step in execution plan: {step}")
    
    # Extract results based on what was actually executed
    analysis_result = task_results.get("ANALYZE", "No analysis performed")
    summary_result = task_results.get("SUMMARIZE", "No summary generated")
    json_result = task_results.get("STRUCTURE", "No JSON structure created")
    
    print(f"\nüé≠ Orchestrator delegation complete!")
    print(f"üìä Tasks executed: {list(task_results.keys())}")
    
    return analysis_result, summary_result, json_result, plan_result

async def save_outputs(summary, json_output):
    """Save analysis outputs to files."""
    
    # Save summary as markdown
    with open("summary.md", "w", encoding="utf-8") as f:
        f.write(summary)
    
    # Save JSON output
    try:
        # Try to parse and format JSON properly
        json_start = json_output.find('{')
        json_end = json_output.rfind('}') + 1
        
        if json_start != -1 and json_end > json_start:
            json_content = json_output[json_start:json_end]
            parsed_json = json.loads(json_content)
            
            with open("details.json", "w", encoding="utf-8") as f:
                json.dump(parsed_json, f, indent=2, ensure_ascii=False)
        else:
            # Save raw output if parsing fails
            with open("details.json", "w", encoding="utf-8") as f:
                f.write(json_output)
                
    except json.JSONDecodeError:
        # Save raw output if parsing fails
        with open("details.json", "w", encoding="utf-8") as f:
            f.write(json_output)

async def display_summary(summary, json_output, plan):
    """Display analysis summary."""
    
    print("\n" + "=" * 60)
    print("üìä ORCHESTRATED ANALYSIS RESULTS")
    print("=" * 60)
    
    print(f"\nüìã Execution Plan Summary:")
    print(f"Tasks completed: {plan.total_tasks}")
    print(f"Execution strategy: {' ‚Üí '.join(plan.execution_order)}")
    
    print(f"\nüìù Summary Preview:")
    summary_lines = summary.split('\n')
    for line in summary_lines[:10]:
        if line.strip():
            print(f"  {line}")
    if len(summary_lines) > 10:
        print(f"  ... ({len(summary_lines) - 10} more lines)")
    
    print(f"\nüîç JSON Analysis Preview:")
    
    try:
        # Try to parse and pretty-print JSON
        json_start = json_output.find('{')
        json_end = json_output.rfind('}') + 1
        
        if json_start != -1 and json_end > json_start:
            json_content = json_output[json_start:json_end]
            parsed_json = json.loads(json_content)
            
            # Display key sections
            print(f"  Summary: {parsed_json.get('summary', 'N/A')}")
            if 'process_info' in parsed_json:
                print(f"  Process: {parsed_json['process_info'].get('command', 'N/A')}")
            if 'phases' in parsed_json:
                print(f"  Phases: {len(parsed_json['phases'])} identified")
            if 'security_observations' in parsed_json:
                print(f"  Security observations: {len(parsed_json['security_observations'])}")
        else:
            print("  Raw JSON output:")
            print("  " + (json_output[:300] + "..." if len(json_output) > 300 else json_output))
            
    except json.JSONDecodeError:
        print("  Raw JSON output:")
        print("  " + (json_output[:300] + "..." if len(json_output) > 300 else json_output))

async def main():
    print("üé≠ Orchestrator-Controlled Security Analysis")
    print("=" * 60)
    
    # Run orchestrated analysis
    analysis, summary, json_output, plan = await run_orchestrated_analysis()
    
    # Save outputs to files
    await save_outputs(summary, json_output)
    
    # Display results
    await display_summary(summary, json_output, plan)
    
    print("\n" + "=" * 60)
    print("‚úÖ Orchestrated analysis complete!")
    print("üìÅ Files generated: summary.md, details.json")
    print("üé≠ Orchestrator successfully coordinated the workflow")
    print("=" * 60)

if __name__ == "__main__":
    asyncio.run(main())
