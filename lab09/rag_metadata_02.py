# Generated by Copilot
import openai
import chromadb
from chromadb.config import Settings

# Set your OpenAI API key

# Use OpenAI's text-embedding-3-small (1536 dimensions)
EMBEDDING_MODEL = "text-embedding-3-small"
EMBEDDING_DIM = 1536

# Initialize ChromaDB client and collection with correct embedding dimension
client = chromadb.Client(Settings())
collection = client.get_or_create_collection(
    name="my_docs",
    embedding_function=None,  # We'll provide embeddings manually
    metadata={"hnsw:space": "cosine"}
)

# Clear existing documents
collection.delete(ids=[f"doc{i}" for i in range(40)])

# Sample public documents
public_docs = [
    "Product roadmap for Q2 includes chatbot enhancements and UI redesign.",
    "Our chatbot now supports voice input for better accessibility.",
    "The new pricing tier will be announced during the June webinar.",
    "Customer satisfaction with support automation increased by 15%.",
    "Public API documentation is now live at api.company.com/docs.",
    "The chatbot handled 12,000 customer interactions last month.",
    "Open beta of our chatbot plugin for Slack starts next week.",
    "New training dataset improves greeting intent accuracy by 9%.",
    "Public case study: Retail chatbot saves 300 hours/month.",
    "Updated terms of service for chatbot usage are now available.",
    "Blog post: How we scaled our chatbot infrastructure in 3 weeks.",
    "Launch recap: Over 2,000 users tested the chatbot on day one.",
    "We're partnering with universities to provide chatbot access.",
    "Survey results: Most requested feature is order tracking.",
    "The chatbot now speaks Dutch and German.",
    "Public changelog updated with March 2025 improvements.",
    "New tutorial video covers chatbot integration in React apps.",
    "Webinar next week: Building inclusive AI for customer service.",
    "We open-sourced our fallback handling module on GitHub.",
    "Customer support chatbot wins industry design award."
]

# Sample confidential documents
conf_docs = [
    "Chatbot error logs revealed edge-case crashes in voice-to-text module. (CONFIDENTIAL)",
    "Internal Slack thread discussed delays in chatbot release. (CONFIDENTIAL)",
    "Legal team flagged GDPR issue in session retention. (CONFIDENTIAL)",
    "The chatbot budget was reduced by 20% last quarter. (CONFIDENTIAL)",
    "Employee IDs were accidentally included in test dataset. (CONFIDENTIAL)",
    "Internal note: chatbot project team facing burnout concerns. (CONFIDENTIAL)",
    "Staging server credentials exposed during CI pipeline. (CONFIDENTIAL)",
    "Meeting notes: execs debated removing chatbot from roadmap. (CONFIDENTIAL)",
    "Strategy pivot: chatbot may be merged into support hub. (CONFIDENTIAL)",
    "Voice data collection policy under legal review. (CONFIDENTIAL)",
    "Security audit uncovered SSO bypass in chatbot admin panel. (CONFIDENTIAL)",
    "Jira ticket shows hardcoded tokens in chatbot training script. (CONFIDENTIAL)",
    "User feedback labeled as toxic was misclassified. (CONFIDENTIAL)",
    "Team leads propose moving chatbot team to Paris office. (CONFIDENTIAL)",
    "Private alpha testing revealed 17% fail rate in routing logic. (CONFIDENTIAL)",
    "AWS costs spiked due to misconfigured chatbot autoscaling. (CONFIDENTIAL)",
    "Confidential roadmap includes HR chatbot for internal onboarding. (CONFIDENTIAL)",
    "Budget request for chatbot training GPU cluster denied. (CONFIDENTIAL)",
    "Chatbot vendor contract ends December 2025. (CONFIDENTIAL)",
    "Pilot with legal chatbot red-flagged by compliance. (CONFIDENTIAL)"
]

# Combine documents and metadata
documents = public_docs + conf_docs
metadatas = [{"access": "public"} for _ in public_docs] + [{"access": "confidential"} for _ in conf_docs]
ids = [f"doc{i}" for i in range(40)]

# Generate embeddings for all documents using OpenAI
def get_embeddings(texts):
    response = openai.embeddings.create(
        input=texts,
        model=EMBEDDING_MODEL
    )
    return [d.embedding for d in response.data]

embeddings = get_embeddings(documents)

# Add documents to ChromaDB with embeddings
collection.add(
    documents=documents,
    metadatas=metadatas,
    ids=ids,
    embeddings=embeddings
)

# Function to print query results
def print_results(title, results):
    print(f"\n=== {title} ===")
    for i, doc in enumerate(results["documents"][0]):
        print(f"Result #{i + 1}")
        print(f"üìÑ Document: {doc}")
        print(f"üè∑Ô∏è  Metadata: {results['metadatas'][0][i]}")
        print(f"üìè Distance: {results['distances'][0][i]:.4f}")
        print("-" * 50)

# Query 1: Public documents
results_public = collection.query(
    query_embeddings=[get_embeddings(["What are the chatbot's new features?"])[0]],
    n_results=3,
    where={"access": "public"}
)
print_results("Query: Only Public Documents", results_public)

# Query 2: Confidential documents
results_conf = collection.query(
    query_embeddings=[get_embeddings(["What internal issues exist with the chatbot?"])[0]],
    n_results=3,
    where={"access": "confidential"}
)
print_results("Query: Only Confidential Documents", results_conf)

# Query 3: All documents
results_all = collection.query(
    query_embeddings=[get_embeddings(["Tell me about the project."])[0]],
    n_results=5,
    where={"access": {"$in": ["public", "confidential"]}}
)
print_results("Query: All Documents", results_all)

# Function to perform RAG using OpenAI GPT-4
def query_rag(question, access_levels=None, n_results=5):
    embedding_response = openai.embeddings.create(
        input=question,
        model=EMBEDDING_MODEL
    )
    query_embedding = embedding_response.data[0].embedding

    # Prepare metadata filter
    where_filter = {}
    if access_levels:
        if isinstance(access_levels, list):
            where_filter = {"access": {"$in": access_levels}}
        else:
            where_filter = {"access": access_levels}

    # Query ChromaDB using the embedding
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=n_results,
        where=where_filter
    )

    # Construct context from retrieved documents
    documents = results.get("documents", [[]])[0]
    context = "\n\n".join(documents)

    # Create prompt for GPT-4
    prompt = f"""
Answer the question using ONLY the context below.

Context:
{context}

Question:
{question}
"""

    # Get response from GPT-4
    response = openai.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )

    return response.choices[0].message.content

# Example usage
answer = query_rag("What are the chatbot's new features?", access_levels=["public"])
print(f"\n=== GPT-4 Response ===\n{answer}")
