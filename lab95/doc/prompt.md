# Analyzing Prompt and Chain Usage in prompt.py
## Introduction
Let’s analyze the following Python code that uses LangChain to generate and analyze a story.
```
from langchain_core.prompts import PromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.output_parsers import StrOutputParser

llm = ChatGoogleGenerativeAI(model="gemini-1.5-pro")

# First chain generates a story
story_prompt = PromptTemplate.from_template("Write a short story about {topic}")
story_chain = story_prompt | llm | StrOutputParser()

# Second chain analyzes the story
analysis_prompt = PromptTemplate.from_template(
    "Analyze the following story's mood:\n{story}"
)
analysis_chain = analysis_prompt | llm | StrOutputParser()

# Combine chains
story_with_analysis = story_chain | analysis_chain

# Run the combined chain
story_analysis = story_with_analysis.invoke({"topic": "a rainy day"})
print("\nAnalysis:", story_analysis)
```

## Step 1
###  Introducing package namespaces
```
from langchain_core.prompts import PromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.output_parsers import StrOutputParser
```
`prompts` and `output_parsers` are submodules within the `langchain_core` package.  
They act like namespaces that group related functionality together, such as prompt templates and output parsing.

## Step 2
### Instantiate the class
This line creates an instance of the `ChatGoogleGenerativeAI` class called `llm`. It will act as a client that will generate and process text.
```
llm = ChatGoogleGenerativeAI(model="gemini-1.5-pro")
```
## Step 3
###  Introducing `prompts`
`PromptTemplate.from_template(...)` creates a prompt with a placeholder `{topic}`, <br>
You can define `{topic}` later, for example by passing `"robots"` or `"space"`, when you invoke the chain.
```
# First chain generates a story
story_prompt = PromptTemplate.from_template("Write a short story about {topic}")
```
## Step 4
### Chains and LangChain Expression Language (LCE)
A chain is a sequence of steps (like `prompt → model → output`) that work together to turn input into meaningful output in LangChain.<br>
**_LangChain Expression Language (LCE)_ **is a simple and readable way to define pipelines using the `|` (pipe) operator.
```
story_chain = story_prompt | llm | StrOutputParser()
```
You can even combine chains
```
# Second chain analyzes the story
analysis_prompt = PromptTemplate.from_template(
    "Analyze the following story's mood:\n{story}"
)
analysis_chain = analysis_prompt | llm | StrOutputParser()
```
_Note: The output of `story_chain` (the generated story) becomes the input for `analysis_chain`._
## Step 5
### Run the combined chain
The `.invoke(...)` method runs the entire combined chain.  
```
story_analysis = story_with_analysis.invoke({"topic": "a rainy day"})
print("\nAnalysis:", story_analysis)
```
This example shows how you can use LangChain to build modular chains that generate and analyze content using prompt templates and language models.

---

[← Back to README](../README.md)

<!-- Generated by Copilot -->

````
