# Generated by Copilot
from agents import Agent, Runner
import asyncio
import json
import os

# Load the document
with open("data/docker-curl-https.txt", "r", encoding="utf-8") as f:
    text = f.read()

# Worker Agents - specialized for different tasks
analyzer_agent = Agent(
    name="Security Trace Analyzer",
    instructions="""You are a security analyst specialized in sysdig trace analysis.

Analyze the provided trace data and extract:
1. Process execution details
2. System call patterns  
3. Network activity
4. File operations
5. Security observations with line numbers

After completing your analysis, hand off to the Summary Generator to create a markdown summary."""
)

summary_agent = Agent(
    name="Summary Generator", 
    instructions="""You are a technical writer specializing in security reports.

Create a concise markdown summary of the security analysis including:
- Executive summary
- Key findings and phases
- Security implications
- Timeline of events

After completing the summary, hand off to the JSON Formatter to structure the data."""
)

json_agent = Agent(
    name="JSON Formatter",
    instructions="""You are a data analyst who structures security analysis into JSON format.

Structure the security analysis into detailed JSON with:
- metadata, summary, process_info
- phases, network_activity, file_operations
- security_observations with line numbers

Output only valid JSON. This is the final step - no further handoffs needed."""
)

# Orchestrator Agent - controls the workflow using handoffs
orchestrator_agent = Agent(
    name="Security Analysis Orchestrator",
    instructions="""You are a workflow orchestrator for security trace analysis.

Your role is to initiate the security analysis workflow by handing off to the Security Trace Analyzer.
The workflow will be: You â†’ Analyzer â†’ Summary Generator â†’ JSON Formatter

Simply hand off the trace data to the Security Trace Analyzer to begin the analysis.""",
    handoffs=[analyzer_agent]
)

# Set up the handoff chain
analyzer_agent.handoffs = [summary_agent]
summary_agent.handoffs = [json_agent]

async def run_orchestrated_analysis():
    """Run orchestrator-controlled security analysis with handoffs."""
    
    print("ğŸ­ Orchestrator-Controlled Security Analysis")
    print("=" * 60)
    print("ğŸ“‹ Starting handoff-based workflow...")
    print("ğŸ”„ Flow: Orchestrator â†’ Analyzer â†’ Summary â†’ JSON")
    
    # The orchestrator will automatically hand off through the chain
    result = await Runner.run(
        orchestrator_agent,
        f"Analyze this sysdig trace data:\n\n{text}"
    )
    
    print(f"\nâœ… Handoff workflow completed!")
    print(f"ğŸ“Š Final result length: {len(result.final_output)} characters")
    
    return result

async def save_outputs(result):
    """Save analysis outputs to files."""
    
    output = result.final_output
    
    # Try to extract different sections from the final output
    # The final output should be JSON from the json_agent
    try:
        # If the final output is JSON, save it as JSON
        json_start = output.find('{')
        json_end = output.rfind('}') + 1
        
        if json_start != -1 and json_end > json_start:
            json_content = output[json_start:json_end]
            parsed_json = json.loads(json_content)
            
            # Save JSON
            with open("details.json", "w", encoding="utf-8") as f:
                json.dump(parsed_json, f, indent=2, ensure_ascii=False)
            
            # Create a summary from the JSON if available
            if 'summary' in parsed_json:
                with open("summary.md", "w", encoding="utf-8") as f:
                    f.write(f"# Security Analysis Summary\n\n{parsed_json['summary']}")
            
            print("ğŸ“ Saved: details.json, summary.md")
        else:
            # Save raw output
            with open("analysis_output.txt", "w", encoding="utf-8") as f:
                f.write(output)
            print("ğŸ“ Saved: analysis_output.txt")
                
    except json.JSONDecodeError:
        # Save raw output if JSON parsing fails
        with open("analysis_output.txt", "w", encoding="utf-8") as f:
            f.write(output)
        print("ğŸ“ Saved: analysis_output.txt")

async def display_summary(result):
    """Display analysis summary."""
    
    print("\n" + "=" * 60)
    print("ğŸ“Š HANDOFF WORKFLOW RESULTS")
    print("=" * 60)
    
    output = result.final_output
    
    print(f"\nğŸ” Final Output Preview (first 500 chars):")
    print(output[:500] + "..." if len(output) > 500 else output)
    
    # Try to parse and display JSON structure if available
    try:
        json_start = output.find('{')
        json_end = output.rfind('}') + 1
        
        if json_start != -1 and json_end > json_start:
            json_content = output[json_start:json_end]
            parsed_json = json.loads(json_content)
            
            print(f"\nğŸ“‹ Structured Analysis:")
            print(f"  Summary: {parsed_json.get('summary', 'N/A')[:100]}...")
            if 'process_info' in parsed_json:
                print(f"  Process: {parsed_json['process_info'].get('command', 'N/A')}")
            if 'phases' in parsed_json:
                print(f"  Phases: {len(parsed_json['phases'])} identified")
            if 'security_observations' in parsed_json:
                print(f"  Security observations: {len(parsed_json['security_observations'])}")
                
    except json.JSONDecodeError:
        print(f"\nğŸ“„ Raw output format (length: {len(output)} chars)")

async def main():
    # Run orchestrated analysis with handoffs
    result = await run_orchestrated_analysis()
    
    # Save outputs to files
    await save_outputs(result)
    
    # Display results
    await display_summary(result)
    
    print("\n" + "=" * 60)
    print("âœ… Orchestrated handoff workflow complete!")
    print("ğŸ­ Agents successfully handed off work through the chain")
    print("=" * 60)

if __name__ == "__main__":
    asyncio.run(main())

async def run_orchestrated_analysis():
    """Run orchestrator-controlled security analysis."""
    
    print("ğŸ“‹ Step 1: Creating execution plan...")
    
    # Get orchestration plan
    plan_run_result = await Runner.run(
        orchestrator_agent,
        f"Create execution plan for analyzing this sysdig trace:\n\n{text[:2000]}..."
    )
    
    # Extract the actual plan data from the RunResult
    plan_result = plan_run_result.final_output
    
    print(f"âœ… Plan created: {plan_result.total_tasks} tasks")
    print(f"ğŸ“Š Execution order: {' â†’ '.join(plan_result.execution_order)}")
    print(f"â±ï¸  Estimated duration: {plan_result.estimated_duration}")
    
    if plan_result.parallel_groups:
        print(f"ğŸ”„ Parallel groups: {list(plan_result.parallel_groups.keys())}")
    
    print("\nğŸ“‹ Step 2: Orchestrator delegating tasks...")
    
    # Create a mapping of task names to agents
    task_agents = {
        "ANALYZE": analyzer_agent,
        "SUMMARIZE": summary_agent,
        "STRUCTURE": json_agent
    }
    
    # Storage for intermediate results
    task_results = {}
    
    # Execute tasks according to the orchestrator's plan
    for step in plan_result.execution_order:
        if step in plan_result.parallel_groups:
            # Handle parallel execution group
            parallel_tasks = plan_result.parallel_groups[step]
            print(f"ï¿½ Orchestrator executing parallel group '{step}': {parallel_tasks}")
            
            # Create tasks for parallel execution
            async_tasks = []
            for task_name in parallel_tasks:
                if task_name == "ANALYZE":
                    # Analysis uses the original text
                    async_tasks.append(
                        Runner.run(task_agents[task_name], text)
                    )
                elif task_name in ["SUMMARIZE", "STRUCTURE"]:
                    # These depend on analysis results
                    if "ANALYZE" in task_results:
                        async_tasks.append(
                            Runner.run(task_agents[task_name], task_results["ANALYZE"])
                        )
                    else:
                        print(f"âš ï¸  Warning: {task_name} depends on ANALYZE but no analysis results available")
                        continue
            
            # Execute parallel tasks
            if async_tasks:
                parallel_results = await asyncio.gather(*async_tasks)
                for i, task_name in enumerate([t for t in parallel_tasks if t in task_agents]):
                    if i < len(parallel_results):
                        task_results[task_name] = parallel_results[i].final_output
                        print(f"âœ… Orchestrator completed: {task_name}")
        
        elif step in task_agents:
            # Handle individual task
            print(f"ğŸ¯ Orchestrator executing: {step}")
            
            if step == "ANALYZE":
                # Analysis uses the original text
                result = await Runner.run(task_agents[step], text)
                task_results[step] = result.final_output
            elif step in ["SUMMARIZE", "STRUCTURE"]:
                # These depend on analysis results
                if "ANALYZE" in task_results:
                    result = await Runner.run(task_agents[step], task_results["ANALYZE"])
                    task_results[step] = result.final_output
                else:
                    print(f"âš ï¸  Warning: {step} depends on ANALYZE but no analysis results available")
                    continue
            
            print(f"âœ… Orchestrator completed: {step}")
        
        else:
            print(f"âš ï¸  Unknown step in execution plan: {step}")
    
    # Extract results based on what was actually executed
    analysis_result = task_results.get("ANALYZE", "No analysis performed")
    summary_result = task_results.get("SUMMARIZE", "No summary generated")
    json_result = task_results.get("STRUCTURE", "No JSON structure created")
    
    print(f"\nğŸ­ Orchestrator delegation complete!")
    print(f"ğŸ“Š Tasks executed: {list(task_results.keys())}")
    
    return analysis_result, summary_result, json_result, plan_result

async def save_outputs(summary, json_output):
    """Save analysis outputs to files."""
    
    # Save summary as markdown
    with open("summary.md", "w", encoding="utf-8") as f:
        f.write(summary)
    
    # Save JSON output
    try:
        # Try to parse and format JSON properly
        json_start = json_output.find('{')
        json_end = json_output.rfind('}') + 1
        
        if json_start != -1 and json_end > json_start:
            json_content = json_output[json_start:json_end]
            parsed_json = json.loads(json_content)
            
            with open("details.json", "w", encoding="utf-8") as f:
                json.dump(parsed_json, f, indent=2, ensure_ascii=False)
        else:
            # Save raw output if parsing fails
            with open("details.json", "w", encoding="utf-8") as f:
                f.write(json_output)
                
    except json.JSONDecodeError:
        # Save raw output if parsing fails
        with open("details.json", "w", encoding="utf-8") as f:
            f.write(json_output)

async def display_summary(summary, json_output, plan):
    """Display analysis summary."""
    
    print("\n" + "=" * 60)
    print("ğŸ“Š ORCHESTRATED ANALYSIS RESULTS")
    print("=" * 60)
    
    print(f"\nğŸ“‹ Execution Plan Summary:")
    print(f"Tasks completed: {plan.total_tasks}")
    print(f"Execution strategy: {' â†’ '.join(plan.execution_order)}")
    
    print(f"\nğŸ“ Summary Preview:")
    summary_lines = summary.split('\n')
    for line in summary_lines[:10]:
        if line.strip():
            print(f"  {line}")
    if len(summary_lines) > 10:
        print(f"  ... ({len(summary_lines) - 10} more lines)")
    
    print(f"\nğŸ” JSON Analysis Preview:")
    
    try:
        # Try to parse and pretty-print JSON
        json_start = json_output.find('{')
        json_end = json_output.rfind('}') + 1
        
        if json_start != -1 and json_end > json_start:
            json_content = json_output[json_start:json_end]
            parsed_json = json.loads(json_content)
            
            # Display key sections
            print(f"  Summary: {parsed_json.get('summary', 'N/A')}")
            if 'process_info' in parsed_json:
                print(f"  Process: {parsed_json['process_info'].get('command', 'N/A')}")
            if 'phases' in parsed_json:
                print(f"  Phases: {len(parsed_json['phases'])} identified")
            if 'security_observations' in parsed_json:
                print(f"  Security observations: {len(parsed_json['security_observations'])}")
        else:
            print("  Raw JSON output:")
            print("  " + (json_output[:300] + "..." if len(json_output) > 300 else json_output))
            
    except json.JSONDecodeError:
        print("  Raw JSON output:")
        print("  " + (json_output[:300] + "..." if len(json_output) > 300 else json_output))

async def main():
    print("ğŸ­ Orchestrator-Controlled Security Analysis")
    print("=" * 60)
    
    # Run orchestrated analysis
    analysis, summary, json_output, plan = await run_orchestrated_analysis()
    
    # Save outputs to files
    await save_outputs(summary, json_output)
    
    # Display results
    await display_summary(summary, json_output, plan)
    
    print("\n" + "=" * 60)
    print("âœ… Orchestrated analysis complete!")
    print("ğŸ“ Files generated: summary.md, details.json")
    print("ğŸ­ Orchestrator successfully coordinated the workflow")
    print("=" * 60)

if __name__ == "__main__":
    asyncio.run(main())
