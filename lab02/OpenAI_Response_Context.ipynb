{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNCebMf6vJGpK43JvvBdtf2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"6SbjDUycdrRS","executionInfo":{"status":"ok","timestamp":1753260691042,"user_tz":-120,"elapsed":1644,"user":{"displayName":"Philippe Bogaerts","userId":"17980485344564371514"}}},"outputs":[],"source":["from openai import OpenAI\n","from google.colab import userdata\n","import os\n"]},{"cell_type":"code","source":["OPEN_API_KEY = userdata.get('OPENAI_API_KEY')\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n"],"metadata":{"id":"wa09Po36eUxg","executionInfo":{"status":"ok","timestamp":1753260699398,"user_tz":-120,"elapsed":1026,"user":{"displayName":"Philippe Bogaerts","userId":"17980485344564371514"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["client = OpenAI()\n"],"metadata":{"id":"qP5LfBjld6cM","executionInfo":{"status":"ok","timestamp":1753260704065,"user_tz":-120,"elapsed":1225,"user":{"displayName":"Philippe Bogaerts","userId":"17980485344564371514"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# ----First Response----\n","response = client.responses.create(\n","    model=\"gpt-4o-mini\",\n","    input=\"tell me a joke\",\n",")\n","print(response.output_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SG4Ckrrtdt2t","executionInfo":{"status":"ok","timestamp":1753260710956,"user_tz":-120,"elapsed":4787,"user":{"displayName":"Philippe Bogaerts","userId":"17980485344564371514"}},"outputId":"7876c18a-795f-4a72-fd3c-1cff5f203826"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["----First Response----\n","Why did the scarecrow win an award?  \n","\n","Because he was outstanding in his field!\n"]}]},{"cell_type":"code","source":["# --- Message recall\n","response_id = response.id\n","response_recall = client.responses.retrieve(response_id)\n","print(response_recall.output_text)\n","print(response_recall)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v4gSCDUvgSWn","executionInfo":{"status":"ok","timestamp":1753261311423,"user_tz":-120,"elapsed":414,"user":{"displayName":"Philippe Bogaerts","userId":"17980485344564371514"}},"outputId":"77b6ab86-2ae1-4e15-a99a-c64e328f9aa3"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Why did the scarecrow win an award?  \n","\n","Because he was outstanding in his field!\n","Response(id='resp_6880a2a38c0c819a84afcf81efb392c4067bce2142edfe56', created_at=1753260707.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[ResponseOutputMessage(id='msg_6880a2a662e8819a961b587406994bb5067bce2142edfe56', content=[ResponseOutputText(annotations=[], text='Why did the scarecrow win an award?  \\n\\nBecause he was outstanding in his field!', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=11, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=19, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=30), user=None, prompt_cache_key=None, safety_identifier=None, store=True)\n"]}]},{"cell_type":"code","source":["# ----Second Response----\n","second_response = client.responses.create(\n","    model=\"gpt-4o-mini\",\n","    previous_response_id=response.id,\n","    input=[{\"role\": \"user\", \"content\": \"explain why this is funny.\"}],\n",")\n","print(second_response.output_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r4-jehHsd0OF","executionInfo":{"status":"ok","timestamp":1753260722657,"user_tz":-120,"elapsed":2332,"user":{"displayName":"Philippe Bogaerts","userId":"17980485344564371514"}},"outputId":"c03a3320-dbe2-403d-de5d-e03368135d7e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["----Second Response----\n","The joke plays on a double meaning. The phrase \"outstanding in his field\" can be interpreted literally—scarecrows stand out in fields to scare away birds—or figuratively, suggesting someone is exceptionally talented in their profession. The unexpected twist between these two meanings creates a lighthearted surprise, which is a key element of humor. The mix of wordplay and imagery makes it amusing!\n"]}]},{"cell_type":"code","source":["# --- Message recall\n","response_id = second_response.id\n","response_recall = client.responses.retrieve(response_id)\n","print(response_recall.output_text)\n","print(response_recall)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2J5Z2nlzfMbp","executionInfo":{"status":"ok","timestamp":1753261283997,"user_tz":-120,"elapsed":349,"user":{"displayName":"Philippe Bogaerts","userId":"17980485344564371514"}},"outputId":"a7fcd944-9294-4564-eb14-1719226b1299"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["The joke plays on a double meaning. The phrase \"outstanding in his field\" can be interpreted literally—scarecrows stand out in fields to scare away birds—or figuratively, suggesting someone is exceptionally talented in their profession. The unexpected twist between these two meanings creates a lighthearted surprise, which is a key element of humor. The mix of wordplay and imagery makes it amusing!\n","Response(id='resp_6880a2b0742c819aa221c6a04afedd66067bce2142edfe56', created_at=1753260720.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[ResponseOutputMessage(id='msg_6880a2b0fce0819a916e008358fc0513067bce2142edfe56', content=[ResponseOutputText(annotations=[], text='The joke plays on a double meaning. The phrase \"outstanding in his field\" can be interpreted literally—scarecrows stand out in fields to scare away birds—or figuratively, suggesting someone is exceptionally talented in their profession. The unexpected twist between these two meanings creates a lighthearted surprise, which is a key element of humor. The mix of wordplay and imagery makes it amusing!', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=None, max_tool_calls=None, previous_response_id='resp_6880a2a38c0c819a84afcf81efb392c4067bce2142edfe56', prompt=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=44, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=80, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=124), user=None, prompt_cache_key=None, safety_identifier=None, store=True)\n"]}]},{"cell_type":"code","source":["# ----3rd Response----\n","third_response = client.responses.create(\n","    model=\"gpt-4o-mini\",\n","    previous_response_id=second_response.id,\n","    input=[{\"role\": \"user\", \"content\": \"Summarise the actions of this thread.\"}],\n",")\n","print(third_response.output_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C4oJEGS2d0aM","executionInfo":{"status":"ok","timestamp":1753260793293,"user_tz":-120,"elapsed":2843,"user":{"displayName":"Philippe Bogaerts","userId":"17980485344564371514"}},"outputId":"599e4808-2718-4bc4-d730-8b492ae50a41"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["1. You asked for a joke.\n","2. I provided a joke about a scarecrow.\n","3. You requested an explanation of why the joke is funny.\n","4. I explained the double meaning and humor behind the joke.\n"]}]},{"cell_type":"code","source":["# --- Message recall\n","response_id = third_response.id\n","response_recall = client.responses.retrieve(response_id)\n","print(response_recall.output_text)\n","print(response_recall)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CWm2mklThVcY","executionInfo":{"status":"ok","timestamp":1753261390344,"user_tz":-120,"elapsed":431,"user":{"displayName":"Philippe Bogaerts","userId":"17980485344564371514"}},"outputId":"dcc6f721-3b84-4d98-9871-e9b8e4b74d4d"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["1. You asked for a joke.\n","2. I provided a joke about a scarecrow.\n","3. You requested an explanation of why the joke is funny.\n","4. I explained the double meaning and humor behind the joke.\n","Response(id='resp_6880a2f68af4819a85c199072747de97067bce2142edfe56', created_at=1753260790.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[ResponseOutputMessage(id='msg_6880a2f857b8819a877de8eb12f4d09e067bce2142edfe56', content=[ResponseOutputText(annotations=[], text='1. You asked for a joke.\\n2. I provided a joke about a scarecrow.\\n3. You requested an explanation of why the joke is funny.\\n4. I explained the double meaning and humor behind the joke.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=None, max_tool_calls=None, previous_response_id='resp_6880a2b0742c819aa221c6a04afedd66067bce2142edfe56', prompt=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=140, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=46, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=186), user=None, prompt_cache_key=None, safety_identifier=None, store=True)\n"]}]}]}