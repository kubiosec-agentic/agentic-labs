# Generated by Copilot
from agents import Agent, Runner, AgentOutputSchema
from pydantic import BaseModel, Field, ConfigDict
import asyncio
import json
import os
from typing import List, Dict, Optional

# Load the document
with open("data/docker-curl-https.txt", "r", encoding="utf-8") as f:
    text = f.read()

class AnalysisTask(BaseModel):
    """Task structure for the orchestrator."""
    model_config = ConfigDict(extra='forbid')
    
    task_type: str
    agent_name: str
    instructions: str
    input_data: str
    depends_on: List[str] = Field(default_factory=list)
    parallel_group: Optional[str] = None

class OrchestratorPlan(BaseModel):
    """Orchestration plan structure."""
    model_config = ConfigDict(extra='forbid')
    
    total_tasks: int
    execution_order: List[str]
    parallel_groups: Dict[str, List[str]]
    estimated_duration: str

# Orchestrator Agent - controls the entire workflow
orchestrator_agent = Agent(
    name="Security Analysis Orchestrator",
    model="gpt-4o-mini",
    instructions="""You are a workflow orchestrator for security trace analysis.

Given a sysdig trace file, create an execution plan with these tasks:
1. ANALYZE - Deep security analysis of the trace
2. SUMMARIZE - Create markdown summary 
3. STRUCTURE - Format as detailed JSON

Plan the workflow considering:
- Task dependencies (SUMMARIZE and STRUCTURE depend on ANALYZE)
- Parallel execution opportunities (SUMMARIZE and STRUCTURE can run in parallel)
- Resource optimization
- Error handling strategies

Return a structured plan with task definitions, execution order, and timing estimates.

Example response:
{
  "total_tasks": 3,
  "execution_order": ["ANALYZE", "SUMMARIZE_AND_STRUCTURE"],
  "parallel_groups": {"SUMMARIZE_AND_STRUCTURE": ["SUMMARIZE", "STRUCTURE"]},
  "estimated_duration": "2-3 minutes"
}""",
    output_type=AgentOutputSchema(OrchestratorPlan, strict_json_schema=False)
)

# Worker Agents (same as before but simplified)
analyzer_agent = Agent(
    name="Security Trace Analyzer",
    model="gpt-4o-mini",
    instructions="""Analyze sysdig trace data and extract:
1. Process execution details
2. System call patterns  
3. Network activity
4. File operations
5. Security observations with line numbers

Provide comprehensive analysis with specific line references."""
)

summary_agent = Agent(
    name="Summary Generator", 
    model="gpt-4o-mini",
    instructions="""Create a concise markdown summary including:
- Executive summary
- Key findings and phases
- Security implications
- Timeline of events

Format as clean markdown."""
)

json_agent = Agent(
    name="JSON Formatter",
    model="gpt-4o-mini",
    instructions="""Structure security analysis into detailed JSON with:
- metadata, summary, process_info
- phases, network_activity, file_operations
- security_observations with line numbers

Output only valid JSON."""
)

async def run_orchestrated_analysis():
    """Run orchestrator-controlled security analysis."""
    
    print("ğŸ“‹ Step 1: Creating execution plan...")
    
    # Get orchestration plan
    plan_result = await Runner.run(
        orchestrator_agent,
        f"Create execution plan for analyzing this sysdig trace:\n\n{text[:2000]}..."
    )
    
    print(f"âœ… Plan created: {plan_result.total_tasks} tasks")
    print(f"ğŸ“Š Execution order: {' â†’ '.join(plan_result.execution_order)}")
    print(f"â±ï¸  Estimated duration: {plan_result.estimated_duration}")
    
    if plan_result.parallel_groups:
        print(f"ğŸ”„ Parallel groups: {list(plan_result.parallel_groups.keys())}")
    
    print("\nğŸ“‹ Step 2: Executing analysis tasks...")
    
    # Execute ANALYZE task
    print("ğŸ” Running security analysis...")
    analysis_result = await Runner.run(analyzer_agent, text)
    
    print("ğŸ“ Running parallel tasks (summary & JSON formatting)...")
    
    # Execute SUMMARIZE and STRUCTURE tasks in parallel
    summary_task = Runner.run(summary_agent, analysis_result)
    json_task = Runner.run(json_agent, analysis_result)
    
    summary_result, json_result = await asyncio.gather(summary_task, json_task)
    
    return analysis_result, summary_result, json_result, plan_result

async def save_outputs(summary, json_output):
    """Save analysis outputs to files."""
    
    # Save summary as markdown
    with open("summary.md", "w", encoding="utf-8") as f:
        f.write(summary)
    
    # Save JSON output
    try:
        # Try to parse and format JSON properly
        json_start = json_output.find('{')
        json_end = json_output.rfind('}') + 1
        
        if json_start != -1 and json_end > json_start:
            json_content = json_output[json_start:json_end]
            parsed_json = json.loads(json_content)
            
            with open("details.json", "w", encoding="utf-8") as f:
                json.dump(parsed_json, f, indent=2, ensure_ascii=False)
        else:
            # Save raw output if parsing fails
            with open("details.json", "w", encoding="utf-8") as f:
                f.write(json_output)
                
    except json.JSONDecodeError:
        # Save raw output if parsing fails
        with open("details.json", "w", encoding="utf-8") as f:
            f.write(json_output)

async def display_summary(summary, json_output, plan):
    """Display analysis summary."""
    
    print("\n" + "=" * 60)
    print("ğŸ“Š ORCHESTRATED ANALYSIS RESULTS")
    print("=" * 60)
    
    print(f"\nğŸ“‹ Execution Plan Summary:")
    print(f"Tasks completed: {plan.total_tasks}")
    print(f"Execution strategy: {' â†’ '.join(plan.execution_order)}")
    
    print(f"\nğŸ“ Summary Preview:")
    summary_lines = summary.split('\n')
    for line in summary_lines[:10]:
        if line.strip():
            print(f"  {line}")
    if len(summary_lines) > 10:
        print(f"  ... ({len(summary_lines) - 10} more lines)")
    
    print(f"\nğŸ” JSON Analysis Preview:")
    
    try:
        # Try to parse and pretty-print JSON
        json_start = json_output.find('{')
        json_end = json_output.rfind('}') + 1
        
        if json_start != -1 and json_end > json_start:
            json_content = json_output[json_start:json_end]
            parsed_json = json.loads(json_content)
            
            # Display key sections
            print(f"  Summary: {parsed_json.get('summary', 'N/A')}")
            if 'process_info' in parsed_json:
                print(f"  Process: {parsed_json['process_info'].get('command', 'N/A')}")
            if 'phases' in parsed_json:
                print(f"  Phases: {len(parsed_json['phases'])} identified")
            if 'security_observations' in parsed_json:
                print(f"  Security observations: {len(parsed_json['security_observations'])}")
        else:
            print("  Raw JSON output:")
            print("  " + (json_output[:300] + "..." if len(json_output) > 300 else json_output))
            
    except json.JSONDecodeError:
        print("  Raw JSON output:")
        print("  " + (json_output[:300] + "..." if len(json_output) > 300 else json_output))

async def main():
    print("ğŸ­ Orchestrator-Controlled Security Analysis")
    print("=" * 60)
    
    # Run orchestrated analysis
    analysis, summary, json_output, plan = await run_orchestrated_analysis()
    
    # Save outputs to files
    await save_outputs(summary, json_output)
    
    # Display results
    await display_summary(summary, json_output, plan)
    
    print("\n" + "=" * 60)
    print("âœ… Orchestrated analysis complete!")
    print("ğŸ“ Files generated: summary.md, details.json")
    print("ğŸ­ Orchestrator successfully coordinated the workflow")
    print("=" * 60)

if __name__ == "__main__":
    asyncio.run(main())
